{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9efbf102-2006-405f-8d9c-f44098e0a865",
   "metadata": {},
   "source": [
    "# MD5 Validator\n",
    "\n",
    "Notebook to validate submitted pdf files against submitted md5 checksums. Student id must be checked manually by a tutor.  \n",
    "\n",
    "The first stage of this notebook takes as input I1: \n",
    "- raw HTML files with submitted md5 from students\n",
    "- raw pdf files submitted by students\n",
    "- csv file with student information (Matrikel, Name, Mail, SS (Startsemester), PO (PrÃ¼fungsordnung))\n",
    "\n",
    "In the first stage we generate the following output s(I1)=O1: \n",
    "- data frame and CSV file with md5 of pdf files\n",
    "- data frame file with submitted md5 from students\n",
    "- data frame and CSV file with valid submissions\n",
    "- data frame and CSV file with invalid submissions\n",
    "\n",
    "In the first stage, we also rename the pdf files according to the valid submissions data frame. After the first stage, the valid pdf files are graded and stored in the korrigiert directory. \n",
    "\n",
    "The second stage takes as input I2: \n",
    "- graded pdf files \n",
    "\n",
    "In the second stage we generate the following output s(I2)=O2: \n",
    "- encrypted graded pdf files\n",
    "\n",
    "After the graded pdf files are encrypted, they are ready to be uploaded publicly. The encrypted files have an owner key that can open all files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d49a042-e70a-4327-95fe-18c6417a7f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE BEFORE RUNNING SCRIPT #\n",
    "path = 't5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8189d30-1df1-4aa1-91f5-45d7d6ea7d90",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4975a0ec-f25e-4965-8cfd-1ff5a332c339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import glob\n",
    "import re\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "import hashlib\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cf3855-b4fc-4142-8149-bf19700bb88c",
   "metadata": {},
   "source": [
    "# Stage 1: Validation\n",
    "\n",
    "In this stage we: \n",
    "- Generate MD5 from uploaded PDF files\n",
    "- Store MD5 from PDF files as data frame A\n",
    "- Scrape MD5 from HTML files\n",
    "- Extract name from HTML files\n",
    "- Store scraped MD5 and extracted names as data frame B\n",
    "- Inner join A and B to determine valid submissions; store the resulting data frame C\n",
    "- Read student id data and store it as data frame D\n",
    "- Inner join C and D to get additional information for the valid submissions; store the resulting data frame E\n",
    "\n",
    "Don't forget to normalize strings and remove whitespaces!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f709e8-214b-45e6-8275-2c7f207b651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_md5(path):\n",
    "    '''\n",
    "    Input: directory with HTML files of MD5 student submissions\n",
    "    Output: list of student submissions as string objects\n",
    "    Comment: Iterate all HTML files in the directory and scrape the submitted MD5s\n",
    "    '''\n",
    "    # list of all html files in the directory\n",
    "    html_files = glob.glob(path + '/*.html')\n",
    "    \n",
    "    # make empty list to append all the matches\n",
    "    match_list = []\n",
    "    \n",
    "    # iterate all html files in the directory and find body (match)\n",
    "    for file in html_files: \n",
    "        # open file\n",
    "        with open(file) as f: \n",
    "            # initiate soup instance\n",
    "            soup = BeautifulSoup(f, 'lxml')\n",
    "            # find body text\n",
    "            match = soup.body.text\n",
    "            # normalize, strip and lower-case the string before appending\n",
    "            match = unicodedata.normalize('NFD', match)\n",
    "            match = match.strip().lower()\n",
    "            match_list.append(match)\n",
    "    # return the list of matches, i.e. body of HTML files\n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79f087-9168-4244-8dbf-cd1780c01b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_names(path): \n",
    "    '''\n",
    "    Input: directory with HTML files of MD5 student submissions\n",
    "    Output: list of student names from MD5 submission\n",
    "    Comment: iterate all HTML files in the directory and extract student name from the file name\n",
    "    '''\n",
    "    # list of all the files in the directory\n",
    "    html_files = glob.glob(path + '/*.html')\n",
    "    # make empty list to append all the matches\n",
    "    match_list = []\n",
    "    # iterate all the files in the directory and find matches\n",
    "    for file in html_files:\n",
    "        # remove directory\n",
    "        file = re.sub(r'\\..+\\/','',file)\n",
    "        # remove everything after the '_'\n",
    "        # everything before the '_' and without the directory is the student name\n",
    "        file = re.sub(r'_.+','',file)\n",
    "        # normalize before appending\n",
    "        file = unicodedata.normalize('NFD', file)\n",
    "        # append the result to the list\n",
    "        match_list.append(file)\n",
    "    # return the list of matches, i.e. student names from submissions\n",
    "    return match_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e4562b-013a-4968-ac30-55f6e698e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_md5(path):\n",
    "    '''\n",
    "    Input: directory with PDF submissions\n",
    "    Output: list of MD5 from PDF submissions\n",
    "    Comment: iterate all files in the path and generate MD5\n",
    "    '''\n",
    "    # list of all the files in the directory\n",
    "    files = glob.glob(path + '/*.*')\n",
    "    # make empty list to append all the matches\n",
    "    md5_list = []\n",
    "    # make set of seen items because there are dups in the directory\n",
    "    seen = set(md5_list)\n",
    "    # iterate all the files in the directory and generate md5 for each of them\n",
    "    # remove dups\n",
    "    for file in files:\n",
    "        # open file in binary format for reading\n",
    "        with open(file, 'rb') as rbf: \n",
    "            # read content of the binary file\n",
    "            content = rbf.read()\n",
    "            # hash the content\n",
    "            h = hashlib.md5(content).hexdigest()\n",
    "            # normalize before appending\n",
    "            h = unicodedata.normalize('NFD', h)\n",
    "            # check if we already saw the hash\n",
    "            if h not in seen: \n",
    "                # add to seen set and list if it's a new hash\n",
    "                seen.add(h)\n",
    "                md5_list.append(h)\n",
    "            else: \n",
    "                # delete dup if we already saw the hash\n",
    "                os.remove(file)\n",
    "    # return the list of MD5s\n",
    "    return md5_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5415c40f-e18e-4b17-84e4-033e04f3e1a3",
   "metadata": {},
   "source": [
    "## Hashes of PDF Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd617735-9a8d-48c0-bcf8-8ae8387f457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe with hashes of submitted PDF files\n",
    "df_pdf = pd.DataFrame({'MD5':file_to_md5(f'./{path}/pdf')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8ee38-47fd-4c24-b716-1e2c67b12424",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb42449-85e2-407d-98ff-2c2168a355bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789d572-be7a-4746-b902-41b938c87914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export hashes of submitted PDF files\n",
    "df_pdf.to_csv(f'./{path}/pdf-hashes.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf7522b-6e2a-4518-bfee-3c1f1e4ce62f",
   "metadata": {},
   "source": [
    "## Hash Submissions with Student Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1aaa344-5b64-4a07-9bc7-215274a8b52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe of submitted hashes and student names\n",
    "df_sub = pd.DataFrame({'MD5':list_md5(f'./{path}/md5'),'Name':list_names(f'./{path}/md5')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7c242-6427-4dc1-802f-003dd2ca0d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4d346f-edfd-47d1-ad54-8ea88d08afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3615da5e-a906-4ba0-866a-baeaf295b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submitted hashes and student names \n",
    "df_sub.to_csv(f'./{path}/md5-sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f28262a-854b-49b1-82e6-e2c1634c140b",
   "metadata": {},
   "source": [
    "## Valid Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8985d4b-8267-4369-9983-a8d9b05fac1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine valid submissions on hash\n",
    "df_valid = pd.merge(df_pdf,df_sub,how='inner',on='MD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dafd0a7-33fd-43d3-a9a9-6637dbdcfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a5cb2c-4a86-40aa-9e1b-dd9aac4e3829",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832460d2-6d33-449d-903f-c0d70911b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f209b-6f74-4e94-ac3a-70b9afc34975",
   "metadata": {},
   "source": [
    "## Invalid Submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4364ca-d0b7-41c1-a86a-46ec9bc0a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF file was submitted with no hash\n",
    "# OR hash was submitted with no PDF file or wrong PDF file\n",
    "df_sub_not_val = pd.merge(df_valid, df_sub, how='outer',on='MD5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bf8d7d-cd2d-4a74-955d-fc3689f03bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val = df_sub_not_val[df_sub_not_val.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a11f5c4-8edd-4227-95e5-8bfd5ffe849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca23663-3a71-4e84-a929-97ea46693dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up dataframe\n",
    "# we export later in the notebook\n",
    "df_sub_not_val = df_sub_not_val.rename(columns={'Name_y':'Name'}).drop('Name_x',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d490b-ed9b-4e8e-85f6-0be3de989fb7",
   "metadata": {},
   "source": [
    "## Student Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13d2a6a-34b7-4c4d-95e7-c8167fe7ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in student information and make dataframe\n",
    "df_id = pd.read_csv('./id_clean_updated_nodups.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3771fc76-4927-471d-b68e-f1b236bb86f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3975d346-85db-4afc-ad72-f830196d6b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize student information\n",
    "df_id['Name'] = df_id['Name'].apply(lambda name : unicodedata.normalize('NFD', name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b8969b-a2f4-4366-bd59-1a62744edac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398653bd-2b28-4ceb-b5f9-a7f340500de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80103d73-f313-475a-94e4-b24317b52255",
   "metadata": {},
   "source": [
    "## Valid Submissions with Student Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d20965c-ca34-445a-81c6-389a62612078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnr = pd.merge(df_valid, df_id, how='inner',on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450439d8-386b-4476-91c9-ea0f1aa85e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638dc4f-e3a1-4e0c-83a5-36367e3c172b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_mnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0d526e-f81e-48f4-a613-b969ee96707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1ed56-c872-4bd3-930b-7129bc7cb220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if this statement is not True, update the student information (student record missing)\n",
    "len(df_valid) == len(df_mnr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad225a74-f6f7-41d4-9731-42ab87dd863d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export valid submission with student information\n",
    "df_mnr.to_csv(f'./{path}/valid-sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b4e120-a2c8-4bf7-84c5-c61f07c3b063",
   "metadata": {},
   "source": [
    "## Invalid Submissions with Student Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181d5c7-c4d6-4a32-81e3-d0e60ad8d0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val = pd.merge(df_sub_not_val,df_id,how='inner',on='Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b13ceba-5ea7-4c10-bd6c-bcb7028cd099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub_not_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0858a4e3-0633-4c36-9e43-84d3d5d351ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sub_not_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62964795-c6f7-48d9-bde5-c57f6feac047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export invalid submission with student information\n",
    "df_sub_not_val.to_csv(f'./{path}/invalid-sub.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a4cc8b-b35c-4bfe-a3aa-6cae930ae7b9",
   "metadata": {},
   "source": [
    "## Rename Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892f0f45-fcfa-493c-b685-1628ef75f9a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create dictionary of hashes\n",
    "md5_dic = df_mnr.to_dict()['MD5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55e6387-d92f-482e-9fcd-c6c090c213bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dicionary of student numbers\n",
    "matrikel_dic = df_mnr.to_dict()['Matrikel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b7d9c1-71b5-43e3-8df7-1161a2c457a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_file(path):\n",
    "    '''\n",
    "    Input: directory with submitted files (no dups)\n",
    "    Output: directory with renamed submitted files (student number)\n",
    "    Comments: most files have a PDF extension but not all\n",
    "    '''\n",
    "    # make list of all the files\n",
    "    files = glob.glob(path + '/*.*')\n",
    "    \n",
    "    # list of non-pdf files\n",
    "    non_pdf = []\n",
    "    \n",
    "    # initiate count\n",
    "    count_pdf_no_hash_sub = 0\n",
    "    \n",
    "    # iterate over each file in the directory\n",
    "    for file in files:\n",
    "        # assume md5 was not submitted\n",
    "        md5_submitted = False\n",
    "        # get file extension\n",
    "        f_name, f_extension = os.path.splitext(file)\n",
    "        \n",
    "        # turn jpeg -> jpg\n",
    "        if f_extension in ['.jpeg','.jpg']: \n",
    "            f_extension = '.jpg'\n",
    "            non_pdf.append(f_name)\n",
    "        \n",
    "        # open the file in read binary mode\n",
    "        with open(file, 'rb') as rbf: \n",
    "            # read contents of the file\n",
    "            content = rbf.read()\n",
    "            # generate hash of the content\n",
    "            h = hashlib.md5(content).hexdigest()\n",
    "            # iterate over dictionary of known valid submissions with known student number\n",
    "            for key, val in md5_dic.items(): \n",
    "                # if the known hash and the generated hash match, rename the file\n",
    "                if val == h: \n",
    "                    os.rename(file, f'./{path}/{matrikel_dic[key]}{f_extension}')\n",
    "                    md5_submitted = True\n",
    "        \n",
    "        # rename the file if hash is not in the valid list and increase count\n",
    "        if md5_submitted == False: \n",
    "            os.rename(file, f'./{path}/no-hash-sub-{count_pdf_no_hash_sub}{f_extension}')\n",
    "            count_pdf_no_hash_sub += 1 \n",
    "    \n",
    "    # print count of PDF submissions where hash was not submitted, i.e. PDF submission is not valid\n",
    "    print(f'Number PDFs with no hash submission: {count_pdf_no_hash_sub}')\n",
    "    print(non_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdfc8d-bf11-473b-b541-25671f0deb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_file(f'./{path}/pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ba6a23-a87a-4366-b252-b159ee7a7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import img2pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59592034-e28b-48fb-a872-31bcfa929847",
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_to_pdf(path):\n",
    "    # make list of graded tests that are jpg\n",
    "    jpg_files = glob.glob(path+'/*.jpg')\n",
    "    \n",
    "    # iterative over list of graded tests that are jpg\n",
    "    for jpg_file in jpg_files:\n",
    "        f_name, f_extension = os.path.splitext(jpg_file)\n",
    "        print(f_name)\n",
    "        # get directory of the test to convert into pdf and encrypt it\n",
    "        test = f'{f_name}.pdf'\n",
    "        # convert jpg into pdf\n",
    "        with open(test,'wb') as f: \n",
    "            f.write(img2pdf.convert(jpg_file))\n",
    "        os.remove(jpg_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6ca6a-b775-4f24-8f0e-9795b73c23b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "turn_to_pdf(f'./{path}/pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496b82c6-4e35-452c-95ef-53f23e4d1dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
